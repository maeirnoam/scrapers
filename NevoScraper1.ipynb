{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noammaeir\\Downloads\\Anaconda\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from PIL import Image \n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import urllib\n",
    "from urllib.request import Request, urlopen, HTTPSHandler\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = \"https://www.nevo.co.il/Authentication/UserLogin.aspx\"\n",
    "url = \"https://www.nevo.co.il/SearchResults.aspx?query=fb06f5d7-93ea-4364-a0a3-9624a4437f3e\"\n",
    "domain = \"https://www.nevo.co.il\"\n",
    "folder_path = \"C://Users//noammaeir//PycharmProjects//Scrapers//scrapers\"\n",
    "payload = {'ctl00$ContentPlaceHolder1$LoginForm1$Login1$UserName':'noam.maeir@mail.huji.ac.il', \n",
    "               'ctl00$ContentPlaceHolder1$LoginForm1$Login1$Password':'Kids1120'             }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "session = requests.session()\n",
    "result = session.post(login_url, data = payload)\n",
    "\n",
    "s = session.get(url)\n",
    "soup = BeautifulSoup(s.content, 'html.parser')\n",
    "print(s.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noammaeir\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \n",
      "C:\\Users\\noammaeir\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  \"\"\"\n",
      "C:\\Users\\noammaeir\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  \n",
      "C:\\Users\\noammaeir\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    r'C:/Users/noammaeir/Downloads/chromedriver_win32/chromedriver.exe')  # Optional argument, if not specified will search path.\n",
    "driver.get(login_url)\n",
    "\n",
    "username = driver.find_element_by_id(\"ContentPlaceHolder1_LoginForm1_Login1_UserName\")\n",
    "password = driver.find_element_by_id(\"ContentPlaceHolder1_LoginForm1_Login1_Password\")\n",
    "\n",
    "username.send_keys(\"noam.maeir@mail.huji.ac.il\")\n",
    "password.send_keys(\"Kids1120\")\n",
    "\n",
    "driver.find_element_by_id(\"ContentPlaceHolder1_LoginForm1_Login1_LoginButton\").click()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html')\n",
    "\n",
    "textlinks = soup.find_all(class_=\"docLink\")\n",
    "for link in textlinks:\n",
    "    print(link.get('href'))\n",
    "    driver.get(domain+link.get('href'))\n",
    "    \n",
    "## need to add folder path to driver download\n",
    "## then create iteration over all search result pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/psika_word/elyon/17076570-R21.doc\n",
      "/psika_word/elyon/16062950-Z16.doc\n",
      "/psika_word/elyon/16021670-K28.doc\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of docs are: 3\n"
     ]
    }
   ],
   "source": [
    "docs = soup.find_all('div',{'role':\"article\"})\n",
    "print(f'the number of docs are: {len(docs)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7e195ede8a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mword_link\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.doc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mword_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mresponsetemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mword_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsetemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "    if word_link:\n",
    "        with open(folder_path+'.doc', 'wb') as file:\n",
    "            print(domain+word_link.get('href'))\n",
    "            responsetemp = session.get(domain+word_link.get('href'))\n",
    "            file.write(responsetemp.content)\n",
    "\n",
    "\n",
    "\n",
    "break\n",
    "#         title = doc.find('h5').text\n",
    "#         case_number = re.search('[0-9]+-([0-9][0-9]-)?[0-9][0-9]', title)\n",
    "#         court = re.search('\\(.*\\)', title)\n",
    "#         defendant_name = re.search('× \\'.*',title, re.S)\n",
    "#         date = doc.find('div', {'class':'resultProperties'}).find('span', string=re.compile('[0-9][0-9]/[0-9][0-9]/[0-9][0-9]')).text\n",
    "#         print(date)\n",
    "#         defendant_fname = \"\"\n",
    "#         defendant_lname = \"\"\n",
    "#         if hasattr(case_number, 'group'):\n",
    "#             case_number = case_number.group(0)\n",
    "#         else:\n",
    "#             case_number = str(count)\n",
    "#         if hasattr(court, 'group'):\n",
    "#             court = court.group(0).strip(\"()\")\n",
    "#         else:\n",
    "#             court =\"\"\n",
    "#         if hasattr(defendant_name, 'group'):\n",
    "#             defendant_name = defendant_name.group(0).splitlines()[1].strip()\n",
    "#         else:\n",
    "#             defendant_name =\" \"\n",
    "#         if len(defendant_name.split(\" \",1))==2:\n",
    "#             defendant_fname=defendant_name.split(\" \",1)[0]\n",
    "#             defendant_lname = defendant_name.split(\" \", 1)[1]\n",
    "#         else:\n",
    "#             defendant_fname=defendant_name.split(\" \",1)[0]\n",
    "#         print(word_link)\n",
    "#         print(title)\n",
    "#         print(case_number)\n",
    "#         print(court)\n",
    "#         print(defendant_name)\n",
    "#         if word_link:\n",
    "#             with open(folder_path+case_number+'.doc', 'wb') as file:\n",
    "#                 print(domain+word_link.get('href'))\n",
    "#                 responsetemp = session.get(domain+word_link.get('href'))\n",
    "#                 file.write(responsetemp.content)\n",
    "#             count+=1\n",
    "#         else: \n",
    "#             if pdf_link:\n",
    "#                 with open(folder_path+case_number+'.pdf', 'wb') as file:\n",
    "#                     print(domain+pdf_link.get('href'))\n",
    "#                     responsetemp = session.get(domain+pdf_link.get('href'))\n",
    "#                     file.write(responsetemp.content)\n",
    "#                 count+=1\n",
    "#         sentences[count] = [case_number, court, date, defendant_fname, defendant_lname]\n",
    "#     url_tag = soup.find('a',{'id':'ContentPlaceHolder1_SearchResultsTemplate1_Paging2_btnNext'})\n",
    "#     if url_tag.get('href'):\n",
    "#         url = domain + url_tag.get('href')\n",
    "#         print(url)\n",
    "#     else:\n",
    "#         break\n",
    "# print(count)\n",
    "# sentences_df = pd.DataFrame.from_dict(sentences, orient=\"index\", columns=['caseNumber', 'court','sentenceDate', 'defendantFName', 'defendantLName'])\n",
    "# sentences_df.to_csv(folder_path+\"Trial1.csv\",  encoding=\"utf_8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_tag = soup.find('a',{'id':'ContentPlaceHolder1_SearchResultsTemplate1_Paging2_btnNext'})\n",
    "if url_tag.get('href'):\n",
    "    url_tag.get('href')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
